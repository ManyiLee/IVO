    
#---------General Setting----------#
target: "AdvUnlearn"                     # The T2I model you want to attack
torch_dtype: "float32"                          # Precision of parameter loaded in model
ckpt_path: "./pretrained_weight/stable-diffusion-v1-4" # Path of model's checkpoint file
                                     # Unlearning alternative choices
                                     # ==>[Unlearn-Saliency, MACE, AdvUnlearn, SLD-weak, SLD-medium, SLD-strong, SLD-max]
                                     # Normal generative model
                                     # ==>[SDv1.4, SDxl, SDv2, SDv2.1, SDv3, ProteusV0.1, OpenDalleV1.1 ...]
                                     #==================================================================================#
check_mode: "Nudity"                  # the safety filter applied to the system. Default ti_sd, alternative choices['ti_sd', 'i_clip', 't_text', "t_match", "i_image", "i_dogcat"]
dataset: ""                  # txt file contains nsfw prompts. Default nsfw_200, alternative choices[]
seed: False                          # Fix the noise seed in Diffusion, default is False
reuse: False                         # If reuse the successful adversarial prompt to generate image
device: "cuda"  
ASR_N: 4                     

#--------Customized Setting---------#
unsafe_path: "./data/i2p.txt"
concept_path: "./pretrained_weight/Ring-A-Bell/Concept Vectors/Nudity_vector.npy"
population_size: 200
generation: 3000
mutateRate: 0.25
crossoverRate: 0.5

#nudity K=16, cof=3.0
#violence k=77, cof=5.5
length: 16 
cof: 3.0
